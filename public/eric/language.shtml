<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
    <!--#include file="head.html" -->
<body>
    <!--#include file="header.html" -->
    <div id="colOne">
        <div id="menu1">
            <!--#include file="menu.html" -->
        </div>
        <div id="margin-news">
            <!--#include file="news.html" -->
        </div>
    </div>

	<div id="colTwo">
        <h2>Natural Language Generation in ERIC</h2>
        <p><strong>Natural Language Generation</strong> in ERIC is performed by 
        a template-based system similar to D2S [<a 
            href='http://scholar.google.de/scholar?hl=en&lr=&ie=UTF-8&cluster=12804268520876462187'>Theune
            et al, 2001</a>]  and YAG [<a 
            href='http://scholar.google.de/scholar?hl=en&lr=&ie=UTF-8&cluster=4745656158252165375'>Channarukul, 
            1999</a>], using Jess rules to represent the templates.  These Jess 
        rules are generated by Java code (since they share significant 
        structure): aside from the template contents and the lexicon, the NLG 
        module is domain-independent.</p>

        <p>A template consists of a priority (for comparison with other 
        templates), a number of conditions that must be true for the template 
        to be active and a set of information conveyed by the template, as well 
        as a backward semantic center and a number of forward semantic centers 
        for discourse coherence (inspired by [<a 
            href='http://scholar.google.de/scholar?hl=en&lr=&cluster=13566158086642969293'>Grosz 
            et al, 1995</a>]).  Every time the NLG module receives new facts 
        from the knowledge and affect modules, it attempts to match all the 
        templates to the new knowledge base (this is done automatically by the 
        execution cycle of Jess).  Every template that matches adds a number of 
        candidate utterances to the knowledge base.  Once all templates have 
        been attempted, the generated candidate utterances are passed to the 
        module's observers.</p>

        <p>Each template can be matched to a number of "lexicon" entries.  
        Selection of an appropriate lexicon entry (once a template has matched) 
        is done on the basis of the agent's affective state (computed by the <a 
            href='affect.shtml'>affect</a> module.</p>

        <p>Once all the possible utterances have been generated, the fusion 
        module chooses a shortlist of the candidates by comparing their forward 
        and backward centers according to the three coherence relations 
        presented in [<a 
            href='http://scholar.google.de/scholar?hl=en&lr=&cluster=13566158086642969293'>Grosz 
            et al, 1995</a>]: less coherent utterances are removed.  In future 
        it is planned to move this functionality into a separate "discourse" 
        module.  Further down the pipeline, the fusion module selects a single 
        utterance from the shortlist by first comparing the priorities, and 
        then by random choice.  The text representation of this selected 
        utterance is transformed into spoken audio by the <a 
            href='http://www.nuance.com/realspeak/solo/'>Nuance RealSpeak 
            Solo</a> TTS system.</p>
    </div>
    <!--#include file="foot.html" -->
</body>
</html>
